services:

  test-lib:
    build:
      context: .
      target: test
      args:
        - TEST_COMMAND=poetry run pytest tests/lib

  test-server:
    build:
      context: .
      target: test
      args:
        - TEST_COMMAND=poetry run pytest tests/server
    
  test-client:
    build:
      context: .
      target: test
      args:
        - TEST_COMMAND=poetry run pytest tests/client
    profiles:
      - client

  server:
    build:
      context: .
      target: production
    command: ["python", "-m", "gunicorn", "-b", "0.0.0.0", "server:app"]
    ports:
      - "8000:8000"
    environment:
      - FLASK_ENV=production
      - APP_PORT=8000
      - KEYS_DIR=keys
      - URL_EXPIRATION=3600
      - TOKEN_EXPIRATION=3600
      - MAX_FILE_NAME_LENGTH=60
      # Make sure these are exported before running the docker-compose command.
      - AWS_REGION=${AWS_REGION} 
      - S3_BUCKET_NAME=${S3_BUCKET_NAME}
      - S3_FOLDER=${S3_FOLDER}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      # - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN} # If using temporary credentials; comment out if not.
    volumes:
      - ./keys:/app/keys
    depends_on:
      - test-lib
      - test-server

  client:
    build:
      context: .
      target: production
    # command: ["tail", "-f", "/dev/null"] # This keep the container alive for manual upload.
    command: ["python", "client.py", "--file", "test_file.txt"] # This automatically tries uploading test_file.txt, which should be present by default.
    environment:
      - PRIVATE_KEYS_PATH=keys/example_private.pem
      - USER=example
      - EMAIL=example@example.com
      - JWT_EXPIRATION=3600
      - SERVER_URL=http://server:8000/api/endpoint
    volumes:
      - ./keys:/app/keys
    depends_on:
      - test-client
      - server
    profiles:
      - client